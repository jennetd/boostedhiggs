{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "import json\n",
    "import uproot3\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "from coffea import processor, util, hist\n",
    "import pickle\n",
    "\n",
    "from plotter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumis = {}\n",
    "lumis['2016'] = 35.9\n",
    "lumis['2017'] = 41.5\n",
    "lumis['2018'] = 59.9\n",
    "\n",
    "with open('xsec.json') as f:\n",
    "  xs = json.load(f)\n",
    "\n",
    "with open('pmap.json') as f:\n",
    "  pmap = json.load(f)\n",
    "\n",
    "systematics = ['nominal',\n",
    "               'jet_triggerUp','jet_triggerDown',\n",
    "               'btagWeightUp','btagWeightDown','btagEffStatUp','btagEffStatDown',\n",
    "               'UESUp','UESDown','JESUp','JESDown','JERUp','JERDown',\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "deta_cut = 3.5\n",
    "mjj_cut = 1000\n",
    "\n",
    "deta_cut_mucr = 0\n",
    "mjj_cut_mucr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2017'\n",
    "nfiles = len(subprocess.getoutput(\"ls infiles-split/\"+year+\"*.json\").split())\n",
    "outsum = processor.dict_accumulator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "repickle=True\n",
    "\n",
    "# Check if pickle exists, and don't re-create it if it does\n",
    "picklename = 'pickles/'+str(year)+'_templates.pkl'\n",
    "if os.path.isfile(picklename):\n",
    "    repickle=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing file 2416 dict_keys(['WJetsToLNu_HT-800To1200_TuneCP5_13TeV-madgraphMLM-pythia8'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/coffea/hist/hist_tools.py:376: RuntimeWarning: Not all requested indices present in <Cat (name=dataset) instance at 0x7fa3e32f0df0>\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load all files - this takes a while\n",
    "if repickle:\n",
    "    nfiles = len(subprocess.getoutput(\"ls infiles-split/\"+year+\"*.json\").split())\n",
    "    for n in range(1,nfiles+1):\n",
    "\n",
    "        with open('infiles-split/'+year+'_'+str(n)+'.json') as f:\n",
    "            infiles = json.load(f)\n",
    "    \n",
    "        filename = '/myeosdir/vbf-category/outfiles/'+year+'_'+str(n)+'.coffea'\n",
    "        if os.path.isfile(filename):\n",
    "            out = util.load(filename)\n",
    "            outsum.add(out)\n",
    "        else:\n",
    "            print('Missing file '+str(n),infiles.keys())\n",
    "            #print(\"File \" + filename + \" is missing\")\n",
    "        \n",
    "    scale_lumi = {k: xs[k] * 1000 *lumis[year] / w for k, w in outsum['sumw'].items()}\n",
    "    outsum['templates-vbf'].scale(scale_lumi, 'dataset')\n",
    "    templates = outsum['templates-vbf'].group('dataset', hist.Cat('process', 'Process'), pmap)\n",
    "\n",
    "    outfile = open(picklename, 'wb')\n",
    "    pickle.dump(templates, outfile, protocol=-1)\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the histogram from the pickle file\n",
    "templates = pickle.load(open(picklename,'rb'))\n",
    "templates_vbf = templates.integrate('region','signal').integrate('deta',int_range=slice(deta_cut,7)).integrate('mjj',int_range=slice(mjj_cut,4000))\n",
    "templates_vbf_mucr = templates.integrate('region','muoncontrol').integrate('deta',int_range=slice(deta_cut_mucr,7)).integrate('mjj',int_range=slice(mjj_cut_mucr,4000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('ZH',): array(0.14997891),\n",
       " ('WH',): array(0.23747442),\n",
       " ('ttH',): array(0.41771698),\n",
       " ('VBF',): array(5.80860424),\n",
       " ('ggF',): array(1.1311812),\n",
       " ('ggF-powheg',): array(3.32933176),\n",
       " ('QCD',): array(203159.14815666),\n",
       " ('VV',): array(48.56485267),\n",
       " ('Wjets',): array(4182.77772778),\n",
       " ('Zjets',): array(1971.98667189),\n",
       " ('ttbar',): array(664.04505709),\n",
       " ('singlet',): array(133.6915826),\n",
       " ('data',): array(178446.),\n",
       " ('muondata',): array(4184.)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "templates_vbf.sum('pt1','msd1').integrate('ddb1',int_range=slice(0,0.89)).integrate('systematic','nominal').values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<StringBin (JERDown) instance at 0x7fa3e3342880>,\n",
       " <StringBin (JERUp) instance at 0x7fa3e33424c0>,\n",
       " <StringBin (JESDown) instance at 0x7fa3e3342d30>,\n",
       " <StringBin (JESUp) instance at 0x7fa3e3342e20>,\n",
       " <StringBin (UESDown) instance at 0x7fa3e3342ca0>,\n",
       " <StringBin (UESUp) instance at 0x7fa3e3342e50>,\n",
       " <StringBin (btagEffStatDown) instance at 0x7fa3e33429d0>,\n",
       " <StringBin (btagEffStatUp) instance at 0x7fa3e3342940>,\n",
       " <StringBin (btagWeightDown) instance at 0x7fa3e3342bb0>,\n",
       " <StringBin (btagWeightUp) instance at 0x7fa42d741d30>,\n",
       " <StringBin (nominal) instance at 0x7fa42d741250>,\n",
       " <StringBin (pileup_weightDown) instance at 0x7fa3e3342640>,\n",
       " <StringBin (pileup_weightUp) instance at 0x7fa3e3342a90>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "templates_vbf.identifiers('systematic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZH\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4bbd12340c5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msystematics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemplates_vbf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pt1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'systematic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ddb1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.89\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'process'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mfout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pass_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemplates_vbf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pt1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'systematic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ddb1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.89\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'process'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mfout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fail_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/hist/export.py\u001b[0m in \u001b[0;36mexport1d\u001b[0;34m(hist)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0msumw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msumw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msumw2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverflow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"all\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverflow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"none\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ()"
     ]
    }
   ],
   "source": [
    "os.system('rm '+year+'/1-signalregion.root')\n",
    "fout = uproot3.create(year+'/1-signalregion.root')\n",
    "for p in pmap.keys():  \n",
    "    if p == \"ttH\" and year == '2016':\n",
    "        continue\n",
    "    print(p)\n",
    "    if \"data\" in p:\n",
    "        s = \"nominal\"\n",
    "        h = templates_vbf.sum('pt1').integrate('systematic',s).integrate('ddb1',int_range=slice(0.89,1)).integrate('process',p)\n",
    "\n",
    "        fout[\"pass_\"+p+\"_\"+s] = hist.export1d(h)\n",
    "        h = templates_vbf.sum('pt1').integrate('systematic',s).integrate('ddb1',int_range=slice(0,0.89)).integrate('process',p)\n",
    "        fout[\"fail_\"+p+\"_\"+s] = hist.export1d(h)\n",
    "    else:\n",
    "        for s in systematics:\n",
    "            h = templates_vbf.sum('pt1').integrate('systematic',s).integrate('ddb1',int_range=slice(0.89,1)).integrate('process',p)\n",
    "            fout[\"pass_\"+p+\"_\"+s] = hist.export1d(h)\n",
    "            h = templates_vbf.sum('pt1').integrate('systematic',s).integrate('ddb1',int_range=slice(0,0.89)).integrate('process',p)\n",
    "            fout[\"fail_\"+p+\"_\"+s] = hist.export1d(h)\n",
    "\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbins = [450, 550, 1200]\n",
    "os.system('rm '+year+'/2pt-signalregion.root')\n",
    "fout = uproot3.create(year+'/2pt-signalregion.root')\n",
    "\n",
    "for i,b in enumerate(ptbins[:-1]):\n",
    "    for p in pmap.keys(): \n",
    "        if p == \"ttH\" and year == '2016':\n",
    "            continue\n",
    "        print(p)\n",
    "        if \"data\" in p:\n",
    "            s = \"nominal\"\n",
    "            h = templates_vbf.integrate('systematic',s).integrate('pt1',int_range=slice(ptbins[i],ptbins[i+1])).integrate('ddb1',int_range=slice(0.89,1)).integrate('process',p)\n",
    "            fout[\"pass_pt\"+str(i+1)+\"_\"+p+\"_\"+s] = hist.export1d(h)\n",
    "            h = templates_vbf.integrate('systematic',s).integrate('pt1',int_range=slice(ptbins[i],ptbins[i+1])).integrate('ddb1',int_range=slice(0,0.89)).integrate('process',p)\n",
    "            fout[\"fail_pt\"+str(i+1)+\"_\"+p+\"_\"+s] = hist.export1d(h)\n",
    "        else:\n",
    "            for s in systematics:\n",
    "                h = templates_vbf.integrate('systematic',s).integrate('pt1',int_range=slice(ptbins[i],ptbins[i+1])).integrate('ddb1',int_range=slice(0.89,1)).integrate('process',p)\n",
    "                fout[\"pass_pt\"+str(i+1)+\"_\"+p+\"_\"+s] = hist.export1d(h)\n",
    "                h = templates_vbf.integrate('systematic',s).integrate('pt1',int_range=slice(ptbins[i],ptbins[i+1])).integrate('ddb1',int_range=slice(0,0.89)).integrate('process',p)\n",
    "                fout[\"fail_pt\"+str(i+1)+\"_\"+p+\"_\"+s] = hist.export1d(h)\n",
    "\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('rm '+year+'/muonCR.root')\n",
    "fout = uproot3.create(year+'/muonCR.root')\n",
    "for p in pmap.keys():  \n",
    "    if p == 'ttH' and year == '2016':\n",
    "        continue\n",
    "    print(p)\n",
    "    if \"data\" in p:\n",
    "        s = \"nominal\"\n",
    "        h = templates_vbf_mucr.integrate('systematic',s).sum('pt1').integrate('ddb1',int_range=slice(0.89,1)).integrate('process',p)\n",
    "        fout[\"pass_\"+p+\"_\"+s] = hist.export1d(h)\n",
    "        h = templates_vbf_mucr.integrate('systematic',s).sum('pt1').integrate('ddb1',int_range=slice(0,0.89)).integrate('process',p)\n",
    "        fout[\"fail_\"+p+\"_\"+s] = hist.export1d(h)\n",
    "    else:\n",
    "        for s in systematics:\n",
    "            h = templates_vbf_mucr.integrate('systematic',s).sum('pt1').integrate('ddb1',int_range=slice(0.89,1)).integrate('process',p)\n",
    "            fout[\"pass_\"+p+\"_\"+s] = hist.export1d(h)\n",
    "            h = templates_vbf_mucr.integrate('systematic',s).sum('pt1').integrate('ddb1',int_range=slice(0,0.89)).integrate('process',p)\n",
    "            fout[\"fail_\"+p+\"_\"+s] = hist.export1d(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
